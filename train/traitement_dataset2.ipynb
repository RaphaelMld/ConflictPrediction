{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "import xgboost as xgb\n",
    "from catboost import CatBoostClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset2 = pd.read_csv('../dataset2/dataset2_before_splitting.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TRAITEMENT SUR LE DATASET 2 (INTERPOLATED)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split en train/test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "## On repasse le type des colonnes 'was_interpolated' en int au lieu de bool\n",
    "\n",
    "cols_to_convert = [\n",
    "    c for c in dataset2.columns \n",
    "    if \"_was_interpolated\" in c\n",
    "]\n",
    "\n",
    "for col in cols_to_convert:\n",
    "    dataset2[col] = dataset2[col].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dataset2 = dataset2.drop(columns=['Unnamed: 0'])\n",
    "#dataset2.to_csv('dalas/project/githubProject/ConflictPrediction/dataset2/dataset2_before_splitting.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train shape: (6610, 166)\n",
      "Test shape: (735, 166)\n"
     ]
    }
   ],
   "source": [
    "## Code pour split le dataset 2 en train/test 90-10 %\n",
    "\n",
    "X = dataset2.drop(columns=['war'])\n",
    "y = dataset2['war']\n",
    "\n",
    "# Split train/test final\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X,y,\n",
    "    test_size=0.1,# 10% pour test\n",
    "    stratify=y, #pour garder la répartition des classes\n",
    "    random_state=42 #pour mettre une random seed fixe\n",
    ")\n",
    "\n",
    "print(\"Train shape:\", X_train.shape)\n",
    "print(\"Test shape:\", X_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Entraînement MLP avec StratifiedKFold + scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- Fold 0 --\n",
      "Accuracy : 0.8903\n",
      "Precision: 0.8660\n",
      "Recall   : 0.8612\n",
      "F1-score : 0.8636\n",
      "-- Fold 1 --\n",
      "Accuracy : 0.9017\n",
      "Precision: 0.8711\n",
      "Recall   : 0.8874\n",
      "F1-score : 0.8792\n",
      "-- Fold 2 --\n",
      "Accuracy : 0.9274\n",
      "Precision: 0.9024\n",
      "Recall   : 0.9193\n",
      "F1-score : 0.9108\n",
      "-- Fold 3 --\n",
      "Accuracy : 0.9032\n",
      "Precision: 0.8872\n",
      "Recall   : 0.8705\n",
      "F1-score : 0.8788\n",
      "-- Fold 4 --\n",
      "Accuracy : 0.8464\n",
      "Precision: 0.8300\n",
      "Recall   : 0.7786\n",
      "F1-score : 0.8035\n",
      "\n",
      "Average metrics over 5 folds:\n",
      "Accuracy  : 0.8938 ± 0.0266\n",
      "Precision : 0.8713 ± 0.0243\n",
      "Recall    : 0.8634 ± 0.0468\n",
      "F1-score  : 0.8672 ± 0.0354\n"
     ]
    }
   ],
   "source": [
    "def pipeline_stratifiedKFold_and_training_MLP(X_train, y_train, k=5):\n",
    "    \n",
    "    list_accuracy_scores = []\n",
    "    list_precision_scores = []\n",
    "    list_recall_scores = []\n",
    "    list_f1_scores = []\n",
    "\n",
    "    # Stratified K-Fold\n",
    "    skf = StratifiedKFold(n_splits=k, shuffle=True, random_state=42)\n",
    "\n",
    "    for i, (train_index, val_index) in enumerate(skf.split(X_train, y_train)):\n",
    "        X_tr = X_train.iloc[train_index]\n",
    "        X_val = X_train.iloc[val_index]\n",
    "        y_tr = y_train.iloc[train_index]\n",
    "        y_val = y_train.iloc[val_index]\n",
    "\n",
    "        print(f\"-- Fold {i} --\")\n",
    "\n",
    "        # Modèle MLP\n",
    "        model = MLPClassifier(\n",
    "            hidden_layer_sizes=(128, 64),\n",
    "            activation='relu',\n",
    "            solver='adam',\n",
    "            max_iter=200,\n",
    "            random_state=42\n",
    "        )\n",
    "\n",
    "        # Entraînement\n",
    "        model.fit(X_tr, y_tr)\n",
    "\n",
    "        # Prédiction\n",
    "        y_pred = model.predict(X_val)\n",
    "\n",
    "        # Métriques\n",
    "        acc = accuracy_score(y_val, y_pred)\n",
    "        prec = precision_score(y_val, y_pred)\n",
    "        rec = recall_score(y_val, y_pred)\n",
    "        f1 = f1_score(y_val, y_pred)\n",
    "\n",
    "        list_accuracy_scores.append(acc)\n",
    "        list_precision_scores.append(prec)\n",
    "        list_recall_scores.append(rec)\n",
    "        list_f1_scores.append(f1)\n",
    "\n",
    "        print(f\"Accuracy : {acc:.4f}\")\n",
    "        print(f\"Precision: {prec:.4f}\")\n",
    "        print(f\"Recall   : {rec:.4f}\")\n",
    "        print(f\"F1-score : {f1:.4f}\")\n",
    "\n",
    "    # Moyenne et écart-type pour chaque métrique\n",
    "    avg_acc, std_acc = np.mean(list_accuracy_scores), np.std(list_accuracy_scores)\n",
    "    avg_prec, std_prec = np.mean(list_precision_scores), np.std(list_precision_scores)\n",
    "    avg_rec, std_rec = np.mean(list_recall_scores), np.std(list_recall_scores)\n",
    "    avg_f1, std_f1 = np.mean(list_f1_scores), np.std(list_f1_scores)\n",
    "\n",
    "    print(\"\\nAverage metrics over {} folds:\".format(k))\n",
    "    print(f\"Accuracy  : {avg_acc:.4f} ± {std_acc:.4f}\")\n",
    "    print(f\"Precision : {avg_prec:.4f} ± {std_prec:.4f}\")\n",
    "    print(f\"Recall    : {avg_rec:.4f} ± {std_rec:.4f}\")\n",
    "    print(f\"F1-score  : {avg_f1:.4f} ± {std_f1:.4f}\")\n",
    "\n",
    "    return ((avg_acc, std_acc), (avg_prec, std_prec), (avg_rec, std_rec), (avg_f1, std_f1))\n",
    "\n",
    "((avg_acc_mlp, std_acc_mlp),\n",
    " (avg_prec_mlp, std_prec_mlp),\n",
    " (avg_rec_mlp, std_rec_mlp),\n",
    " (avg_f1_mlp, std_f1_mlp)) = pipeline_stratifiedKFold_and_training_MLP(X_train, y_train, k=5)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Entraînement XGBoost avec StratifiedKFold + scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SKF avec K =10 (on garde le même skf pour avoir la meme répartition)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- Fold 0 --\n",
      "Accuracy : 0.9470\n",
      "Precision: 0.9462\n",
      "Recall   : 0.9213\n",
      "F1-score : 0.9336\n",
      "-- Fold 1 --\n",
      "Accuracy : 0.9455\n",
      "Precision: 0.9326\n",
      "Recall   : 0.9326\n",
      "F1-score : 0.9326\n",
      "-- Fold 2 --\n",
      "Accuracy : 0.9486\n",
      "Precision: 0.9464\n",
      "Recall   : 0.9251\n",
      "F1-score : 0.9356\n",
      "-- Fold 3 --\n",
      "Accuracy : 0.9531\n",
      "Precision: 0.9538\n",
      "Recall   : 0.9288\n",
      "F1-score : 0.9412\n",
      "-- Fold 4 --\n",
      "Accuracy : 0.9516\n",
      "Precision: 0.9608\n",
      "Recall   : 0.9176\n",
      "F1-score : 0.9387\n",
      "-- Fold 5 --\n",
      "Accuracy : 0.9546\n",
      "Precision: 0.9504\n",
      "Recall   : 0.9361\n",
      "F1-score : 0.9432\n",
      "-- Fold 6 --\n",
      "Accuracy : 0.9531\n",
      "Precision: 0.9273\n",
      "Recall   : 0.9586\n",
      "F1-score : 0.9427\n",
      "-- Fold 7 --\n",
      "Accuracy : 0.9516\n",
      "Precision: 0.9432\n",
      "Recall   : 0.9361\n",
      "F1-score : 0.9396\n",
      "-- Fold 8 --\n",
      "Accuracy : 0.9259\n",
      "Precision: 0.9094\n",
      "Recall   : 0.9060\n",
      "F1-score : 0.9077\n",
      "-- Fold 9 --\n",
      "Accuracy : 0.9576\n",
      "Precision: 0.9612\n",
      "Recall   : 0.9323\n",
      "F1-score : 0.9466\n",
      "\n",
      "Average metrics over 10 folds:\n",
      "Accuracy  : 0.9489 ± 0.0084\n",
      "Precision : 0.9431 ± 0.0152\n",
      "Recall    : 0.9295 ± 0.0132\n",
      "F1-score  : 0.9361 ± 0.0104\n"
     ]
    }
   ],
   "source": [
    "def pipeline_stratifiedKFold_and_training_XGBoost(X_train, y_train, k=10):\n",
    "    \n",
    "    list_accuracy_scores = []\n",
    "    list_precision_scores = []\n",
    "    list_recall_scores = []\n",
    "    list_f1_scores = []\n",
    "\n",
    "    # Stratified K-Fold\n",
    "    skf = StratifiedKFold(n_splits=k, shuffle=True, random_state=42) # On garde le même skf pour la comparaison\n",
    "\n",
    "    for i, (train_index, val_index) in enumerate(skf.split(X_train, y_train)):\n",
    "        X_tr = X_train.iloc[train_index]\n",
    "        X_val = X_train.iloc[val_index]\n",
    "        y_tr = y_train.iloc[train_index]\n",
    "        y_val = y_train.iloc[val_index]\n",
    "\n",
    "        print(f\"-- Fold {i} --\")\n",
    "\n",
    "        # Modèle MLP\n",
    "        model = xgb.XGBClassifier( # Hyperparamètres à revoir\n",
    "            n_estimators=100,\n",
    "            max_depth=5,\n",
    "            learning_rate=1,\n",
    "            random_state=42\n",
    "        )\n",
    "\n",
    "        # Entraînement\n",
    "        model.fit(X_tr, y_tr)\n",
    "\n",
    "        # Prédiction\n",
    "        y_pred = model.predict(X_val)\n",
    "\n",
    "        # Calcul des métriques\n",
    "        acc = accuracy_score(y_val, y_pred)\n",
    "        prec = precision_score(y_val, y_pred)\n",
    "        rec = recall_score(y_val, y_pred)\n",
    "        f1 = f1_score(y_val, y_pred)\n",
    "\n",
    "        list_accuracy_scores.append(acc)\n",
    "        list_precision_scores.append(prec)\n",
    "        list_recall_scores.append(rec)\n",
    "        list_f1_scores.append(f1)\n",
    "\n",
    "        print(f\"Accuracy : {acc:.4f}\")\n",
    "        print(f\"Precision: {prec:.4f}\")\n",
    "        print(f\"Recall   : {rec:.4f}\")\n",
    "        print(f\"F1-score : {f1:.4f}\")\n",
    "\n",
    "    # Moyenne et écart-type pour chaque métrique\n",
    "    avg_acc, std_acc = np.mean(list_accuracy_scores), np.std(list_accuracy_scores)\n",
    "    avg_prec, std_prec = np.mean(list_precision_scores), np.std(list_precision_scores)\n",
    "    avg_rec, std_rec = np.mean(list_recall_scores), np.std(list_recall_scores)\n",
    "    avg_f1, std_f1 = np.mean(list_f1_scores), np.std(list_f1_scores)\n",
    "\n",
    "    print(\"\\nAverage metrics over {} folds:\".format(k))\n",
    "    print(f\"Accuracy  : {avg_acc:.4f} ± {std_acc:.4f}\")\n",
    "    print(f\"Precision : {avg_prec:.4f} ± {std_prec:.4f}\")\n",
    "    print(f\"Recall    : {avg_rec:.4f} ± {std_rec:.4f}\")\n",
    "    print(f\"F1-score  : {avg_f1:.4f} ± {std_f1:.4f}\")\n",
    "\n",
    "    return ((avg_acc, std_acc), (avg_prec, std_prec), (avg_rec, std_rec), (avg_f1, std_f1))\n",
    "\n",
    "# Exécution sur le dataset 2\n",
    "((avg_acc_xgb, std_acc_xgb),\n",
    " (avg_prec_xgb, std_prec_xgb),\n",
    " (avg_rec_xgb, std_rec_xgb),\n",
    " (avg_f1_xgb, std_f1_xgb)) = pipeline_stratifiedKFold_and_training_XGBoost(X_train, y_train, k=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Entraînement CatBoost avec StratifiedKFold + scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 0\n",
      "Accuracy : 0.9077\n",
      "Precision: 0.9055\n",
      "Recall   : 0.8614\n",
      "F1-score : 0.8829\n",
      "Fold 1\n",
      "Accuracy : 0.9304\n",
      "Precision: 0.9266\n",
      "Recall   : 0.8989\n",
      "F1-score : 0.9125\n",
      "Fold 2\n",
      "Accuracy : 0.9395\n",
      "Precision: 0.9486\n",
      "Recall   : 0.8989\n",
      "F1-score : 0.9231\n",
      "Fold 3\n",
      "Accuracy : 0.9289\n",
      "Precision: 0.9435\n",
      "Recall   : 0.8764\n",
      "F1-score : 0.9087\n",
      "Fold 4\n",
      "Accuracy : 0.9259\n",
      "Precision: 0.9325\n",
      "Recall   : 0.8801\n",
      "F1-score : 0.9056\n",
      "Fold 5\n",
      "Accuracy : 0.9259\n",
      "Precision: 0.9323\n",
      "Recall   : 0.8797\n",
      "F1-score : 0.9052\n",
      "Fold 6\n",
      "Accuracy : 0.9274\n",
      "Precision: 0.9431\n",
      "Recall   : 0.8722\n",
      "F1-score : 0.9062\n",
      "Fold 7\n",
      "Accuracy : 0.9259\n",
      "Precision: 0.9357\n",
      "Recall   : 0.8759\n",
      "F1-score : 0.9049\n",
      "Fold 8\n",
      "Accuracy : 0.9017\n",
      "Precision: 0.9205\n",
      "Recall   : 0.8271\n",
      "F1-score : 0.8713\n",
      "Fold 9\n",
      "Accuracy : 0.9183\n",
      "Precision: 0.9344\n",
      "Recall   : 0.8571\n",
      "F1-score : 0.8941\n",
      "\n",
      "Average metrics over 10 folds:\n",
      "Accuracy  : 0.9231 ± 0.0106\n",
      "Precision : 0.9323 ± 0.0119\n",
      "Recall    : 0.8728 ± 0.0199\n",
      "F1-score  : 0.9015 ± 0.0142\n"
     ]
    }
   ],
   "source": [
    "def pipeline_stratifiedKFold_and_training_CatBoost(X_train, y_train, k=10):\n",
    "\n",
    "    list_accuracy_scores = []\n",
    "    list_precision_scores = []\n",
    "    list_recall_scores = []\n",
    "    list_f1_scores = []\n",
    "    skf = StratifiedKFold(n_splits=k, shuffle=True, random_state=42)\n",
    "\n",
    "    for i, (train_index, val_index) in enumerate(skf.split(X_train, y_train)):\n",
    "\n",
    "        # Récupération des sous-ensembles\n",
    "        X_tr = X_train.iloc[train_index]\n",
    "        X_val = X_train.iloc[val_index]\n",
    "        y_tr = y_train.iloc[train_index]\n",
    "        y_val = y_train.iloc[val_index]\n",
    "\n",
    "        print(f\"Fold {i}\")\n",
    "\n",
    "        # Modèle CatBoost\n",
    "        model = CatBoostClassifier(\n",
    "            iterations=300,\n",
    "            learning_rate=0.05,\n",
    "            depth=6,\n",
    "            loss_function=\"Logloss\",\n",
    "            eval_metric=\"F1\",\n",
    "            random_seed=42,\n",
    "            verbose=False\n",
    "        )\n",
    "\n",
    "        # Entraînement\n",
    "        model.fit(X_tr, y_tr)\n",
    "\n",
    "        # Prédiction\n",
    "        y_pred = model.predict(X_val)\n",
    "\n",
    "        # Métriques\n",
    "        acc = accuracy_score(y_val, y_pred)\n",
    "        prec = precision_score(y_val, y_pred)\n",
    "        rec = recall_score(y_val, y_pred)\n",
    "        f1 = f1_score(y_val, y_pred)\n",
    "\n",
    "        list_accuracy_scores.append(acc)\n",
    "        list_precision_scores.append(prec)\n",
    "        list_recall_scores.append(rec)\n",
    "        list_f1_scores.append(f1)\n",
    "\n",
    "        print(f\"Accuracy : {acc:.4f}\")\n",
    "        print(f\"Precision: {prec:.4f}\")\n",
    "        print(f\"Recall   : {rec:.4f}\")\n",
    "        print(f\"F1-score : {f1:.4f}\")\n",
    "\n",
    "    # Moyenne et écart-type pour chaque métrique\n",
    "    avg_acc, std_acc = np.mean(list_accuracy_scores), np.std(list_accuracy_scores)\n",
    "    avg_prec, std_prec = np.mean(list_precision_scores), np.std(list_precision_scores)\n",
    "    avg_rec, std_rec = np.mean(list_recall_scores), np.std(list_recall_scores)\n",
    "    avg_f1, std_f1 = np.mean(list_f1_scores), np.std(list_f1_scores)\n",
    "\n",
    "    print(\"\\nAverage metrics over {} folds:\".format(k))\n",
    "    print(f\"Accuracy  : {avg_acc:.4f} ± {std_acc:.4f}\")\n",
    "    print(f\"Precision : {avg_prec:.4f} ± {std_prec:.4f}\")\n",
    "    print(f\"Recall    : {avg_rec:.4f} ± {std_rec:.4f}\")\n",
    "    print(f\"F1-score  : {avg_f1:.4f} ± {std_f1:.4f}\")\n",
    "\n",
    "    return ((avg_acc, std_acc), (avg_prec, std_prec), (avg_rec, std_rec), (avg_f1, std_f1))\n",
    "\n",
    "((avg_acc_cb, std_acc_cb),\n",
    " (avg_prec_cb, std_prec_cb),\n",
    " (avg_rec_cb, std_rec_cb), \n",
    " (avg_f1_cb, std_f1_cb)) = pipeline_stratifiedKFold_and_training_CatBoost(X_train, y_train, k=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Entraînement GradientBoosting avec StratifiedKFold + scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- Fold 0 --\n",
      "Accuracy : 0.7806\n",
      "Precision: 0.8020\n",
      "Recall   : 0.6067\n",
      "F1-score : 0.6908\n",
      "-- Fold 1 --\n",
      "Accuracy : 0.7791\n",
      "Precision: 0.7951\n",
      "Recall   : 0.6105\n",
      "F1-score : 0.6907\n",
      "-- Fold 2 --\n",
      "Accuracy : 0.7685\n",
      "Precision: 0.8032\n",
      "Recall   : 0.5655\n",
      "F1-score : 0.6637\n",
      "-- Fold 3 --\n",
      "Accuracy : 0.7897\n",
      "Precision: 0.8636\n",
      "Recall   : 0.5693\n",
      "F1-score : 0.6862\n",
      "-- Fold 4 --\n",
      "Accuracy : 0.7973\n",
      "Precision: 0.8595\n",
      "Recall   : 0.5955\n",
      "F1-score : 0.7035\n",
      "-- Fold 5 --\n",
      "Accuracy : 0.7716\n",
      "Precision: 0.8286\n",
      "Recall   : 0.5451\n",
      "F1-score : 0.6576\n",
      "-- Fold 6 --\n",
      "Accuracy : 0.7700\n",
      "Precision: 0.8032\n",
      "Recall   : 0.5677\n",
      "F1-score : 0.6652\n",
      "-- Fold 7 --\n",
      "Accuracy : 0.7821\n",
      "Precision: 0.8547\n",
      "Recall   : 0.5526\n",
      "F1-score : 0.6712\n",
      "-- Fold 8 --\n",
      "Accuracy : 0.7670\n",
      "Precision: 0.7917\n",
      "Recall   : 0.5714\n",
      "F1-score : 0.6638\n",
      "-- Fold 9 --\n",
      "Accuracy : 0.7927\n",
      "Precision: 0.8486\n",
      "Recall   : 0.5902\n",
      "F1-score : 0.6962\n",
      "\n",
      "Average metrics over 10 folds:\n",
      "Accuracy  : 0.7799 ± 0.0102\n",
      "Precision : 0.8250 ± 0.0276\n",
      "Recall    : 0.5775 ± 0.0211\n",
      "F1-score  : 0.6789 ± 0.0155\n"
     ]
    }
   ],
   "source": [
    "def pipeline_stratifiedKFold_and_training_GB(X_train, y_train, k=10):\n",
    "\n",
    "    list_accuracy_scores = []\n",
    "    list_precision_scores = []\n",
    "    list_recall_scores = []\n",
    "    list_f1_scores = []\n",
    "\n",
    "    skf = StratifiedKFold(n_splits=k, shuffle=True, random_state=42)\n",
    "\n",
    "    for i, (train_index, val_index) in enumerate(skf.split(X_train, y_train)):\n",
    "        X_tr = X_train.iloc[train_index]\n",
    "        X_val = X_train.iloc[val_index]\n",
    "        y_tr = y_train.iloc[train_index]\n",
    "        y_val = y_train.iloc[val_index]\n",
    "\n",
    "        print(f\"-- Fold {i} --\")\n",
    "\n",
    "        # Modèle Gradient Boosting\n",
    "        modelGB = GradientBoostingClassifier(\n",
    "            n_estimators=200,\n",
    "            learning_rate=0.05,\n",
    "            max_depth=3\n",
    "        )\n",
    "\n",
    "        # Entraînement\n",
    "        modelGB.fit(X_tr, y_tr)\n",
    "\n",
    "        # Prédiction\n",
    "        y_predGB = modelGB.predict(X_val)\n",
    "\n",
    "        # Calcul des métriques\n",
    "        acc = accuracy_score(y_val, y_predGB)\n",
    "        prec = precision_score(y_val, y_predGB)\n",
    "        rec = recall_score(y_val, y_predGB)\n",
    "        f1 = f1_score(y_val, y_predGB)\n",
    "\n",
    "        list_accuracy_scores.append(acc)\n",
    "        list_precision_scores.append(prec)\n",
    "        list_recall_scores.append(rec)\n",
    "        list_f1_scores.append(f1)\n",
    "\n",
    "        print(f\"Accuracy : {acc:.4f}\")\n",
    "        print(f\"Precision: {prec:.4f}\")\n",
    "        print(f\"Recall   : {rec:.4f}\")\n",
    "        print(f\"F1-score : {f1:.4f}\")\n",
    "\n",
    "    # Moyenne et écart-type\n",
    "    avg_acc, std_acc = np.mean(list_accuracy_scores), np.std(list_accuracy_scores)\n",
    "    avg_prec, std_prec = np.mean(list_precision_scores), np.std(list_precision_scores)\n",
    "    avg_rec, std_rec = np.mean(list_recall_scores), np.std(list_recall_scores)\n",
    "    avg_f1, std_f1 = np.mean(list_f1_scores), np.std(list_f1_scores)\n",
    "\n",
    "    print(\"\\nAverage metrics over {} folds:\".format(k))\n",
    "    print(f\"Accuracy  : {avg_acc:.4f} ± {std_acc:.4f}\")\n",
    "    print(f\"Precision : {avg_prec:.4f} ± {std_prec:.4f}\")\n",
    "    print(f\"Recall    : {avg_rec:.4f} ± {std_rec:.4f}\")\n",
    "    print(f\"F1-score  : {avg_f1:.4f} ± {std_f1:.4f}\")\n",
    "\n",
    "    return ((avg_acc, std_acc), (avg_prec, std_prec), (avg_rec, std_rec), (avg_f1, std_f1))\n",
    "\n",
    "# Exécution\n",
    "((avg_acc_gb, std_acc_gb),\n",
    " (avg_prec_gb, std_prec_gb),\n",
    " (avg_rec_gb, std_rec_gb),\n",
    " (avg_f1_gb, std_f1_gb)) = pipeline_stratifiedKFold_and_training_GB(X_train, y_train, k=10)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Entraînement ExtraTrees avec StratifiedKFold + scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- Fold 0 --\n",
      "Accuracy : 0.9728\n",
      "Precision: 0.9698\n",
      "Recall   : 0.9625\n",
      "F1-score : 0.9662\n",
      "-- Fold 1 --\n",
      "Accuracy : 0.9607\n",
      "Precision: 0.9582\n",
      "Recall   : 0.9438\n",
      "F1-score : 0.9509\n",
      "-- Fold 2 --\n",
      "Accuracy : 0.9773\n",
      "Precision: 0.9737\n",
      "Recall   : 0.9700\n",
      "F1-score : 0.9719\n",
      "-- Fold 3 --\n",
      "Accuracy : 0.9607\n",
      "Precision: 0.9513\n",
      "Recall   : 0.9513\n",
      "F1-score : 0.9513\n",
      "-- Fold 4 --\n",
      "Accuracy : 0.9713\n",
      "Precision: 0.9627\n",
      "Recall   : 0.9663\n",
      "F1-score : 0.9645\n",
      "-- Fold 5 --\n",
      "Accuracy : 0.9758\n",
      "Precision: 0.9845\n",
      "Recall   : 0.9549\n",
      "F1-score : 0.9695\n",
      "-- Fold 6 --\n",
      "Accuracy : 0.9743\n",
      "Precision: 0.9734\n",
      "Recall   : 0.9624\n",
      "F1-score : 0.9679\n",
      "-- Fold 7 --\n",
      "Accuracy : 0.9697\n",
      "Precision: 0.9695\n",
      "Recall   : 0.9549\n",
      "F1-score : 0.9621\n",
      "-- Fold 8 --\n",
      "Accuracy : 0.9546\n",
      "Precision: 0.9504\n",
      "Recall   : 0.9361\n",
      "F1-score : 0.9432\n",
      "-- Fold 9 --\n",
      "Accuracy : 0.9682\n",
      "Precision: 0.9767\n",
      "Recall   : 0.9436\n",
      "F1-score : 0.9598\n",
      "\n",
      "Average metrics over 10 folds:\n",
      "Accuracy  : 0.9685 ± 0.0071\n",
      "Precision : 0.9670 ± 0.0106\n",
      "Recall    : 0.9546 ± 0.0104\n",
      "F1-score  : 0.9607 ± 0.0089\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "import numpy as np\n",
    "\n",
    "def pipeline_stratifiedKFold_and_training_ET(X_train, y_train, k=10):\n",
    "\n",
    "    list_accuracy_scores = []\n",
    "    list_precision_scores = []\n",
    "    list_recall_scores = []\n",
    "    list_f1_scores = []\n",
    "\n",
    "    skf = StratifiedKFold(n_splits=k, shuffle=True, random_state=42)\n",
    "\n",
    "    for i, (train_index, val_index) in enumerate(skf.split(X_train, y_train)):\n",
    "        X_tr = X_train.iloc[train_index]\n",
    "        X_val = X_train.iloc[val_index]\n",
    "        y_tr = y_train.iloc[train_index]\n",
    "        y_val = y_train.iloc[val_index]\n",
    "\n",
    "        print(f\"-- Fold {i} --\")\n",
    "\n",
    "        # Modèle ExtraTrees\n",
    "        modelET = ExtraTreesClassifier(\n",
    "            n_estimators=300,\n",
    "            max_depth=None,\n",
    "            random_state=42,\n",
    "            n_jobs=-1\n",
    "        )\n",
    "\n",
    "        # Entraînement\n",
    "        modelET.fit(X_tr, y_tr)\n",
    "\n",
    "        # Prédiction\n",
    "        y_predET = modelET.predict(X_val)\n",
    "\n",
    "        # Métriques\n",
    "        acc = accuracy_score(y_val, y_predET)\n",
    "        prec = precision_score(y_val, y_predET)\n",
    "        rec = recall_score(y_val, y_predET)\n",
    "        f1 = f1_score(y_val, y_predET)\n",
    "\n",
    "        list_accuracy_scores.append(acc)\n",
    "        list_precision_scores.append(prec)\n",
    "        list_recall_scores.append(rec)\n",
    "        list_f1_scores.append(f1)\n",
    "\n",
    "        print(f\"Accuracy : {acc:.4f}\")\n",
    "        print(f\"Precision: {prec:.4f}\")\n",
    "        print(f\"Recall   : {rec:.4f}\")\n",
    "        print(f\"F1-score : {f1:.4f}\")\n",
    "\n",
    "    # Moyenne et écart-type\n",
    "    avg_acc, std_acc = np.mean(list_accuracy_scores), np.std(list_accuracy_scores)\n",
    "    avg_prec, std_prec = np.mean(list_precision_scores), np.std(list_precision_scores)\n",
    "    avg_rec, std_rec = np.mean(list_recall_scores), np.std(list_recall_scores)\n",
    "    avg_f1, std_f1 = np.mean(list_f1_scores), np.std(list_f1_scores)\n",
    "\n",
    "    print(\"\\nAverage metrics over {} folds:\".format(k))\n",
    "    print(f\"Accuracy  : {avg_acc:.4f} ± {std_acc:.4f}\")\n",
    "    print(f\"Precision : {avg_prec:.4f} ± {std_prec:.4f}\")\n",
    "    print(f\"Recall    : {avg_rec:.4f} ± {std_rec:.4f}\")\n",
    "    print(f\"F1-score  : {avg_f1:.4f} ± {std_f1:.4f}\")\n",
    "\n",
    "    return ((avg_acc, std_acc), (avg_prec, std_prec), (avg_rec, std_rec), (avg_f1, std_f1))\n",
    "\n",
    "# Exécution\n",
    "((avg_acc_et, std_acc_et),\n",
    " (avg_prec_et, std_prec_et),\n",
    " (avg_rec_et, std_rec_et),\n",
    " (avg_f1_et, std_f1_et)) = pipeline_stratifiedKFold_and_training_ET(X_train, y_train, k=10)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Entraînement RandomForest avec StratifiedKFold + scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 0\n",
      "Accuracy : 0.9516\n",
      "Precision: 0.9572\n",
      "Recall   : 0.9213\n",
      "F1-score : 0.9389\n",
      "Fold 1\n",
      "Accuracy : 0.9516\n",
      "Precision: 0.9537\n",
      "Recall   : 0.9251\n",
      "F1-score : 0.9392\n",
      "Fold 2\n",
      "Accuracy : 0.9622\n",
      "Precision: 0.9549\n",
      "Recall   : 0.9513\n",
      "F1-score : 0.9531\n",
      "Fold 3\n",
      "Accuracy : 0.9592\n",
      "Precision: 0.9688\n",
      "Recall   : 0.9288\n",
      "F1-score : 0.9484\n",
      "Fold 4\n",
      "Accuracy : 0.9561\n",
      "Precision: 0.9648\n",
      "Recall   : 0.9251\n",
      "F1-score : 0.9446\n",
      "Fold 5\n",
      "Accuracy : 0.9652\n",
      "Precision: 0.9841\n",
      "Recall   : 0.9286\n",
      "F1-score : 0.9555\n",
      "Fold 6\n",
      "Accuracy : 0.9713\n",
      "Precision: 0.9805\n",
      "Recall   : 0.9474\n",
      "F1-score : 0.9637\n",
      "Fold 7\n",
      "Accuracy : 0.9561\n",
      "Precision: 0.9611\n",
      "Recall   : 0.9286\n",
      "F1-score : 0.9446\n",
      "Fold 8\n",
      "Accuracy : 0.9410\n",
      "Precision: 0.9558\n",
      "Recall   : 0.8947\n",
      "F1-score : 0.9243\n",
      "Fold 9\n",
      "Accuracy : 0.9546\n",
      "Precision: 0.9646\n",
      "Recall   : 0.9211\n",
      "F1-score : 0.9423\n",
      "\n",
      "Average metrics over 10 folds:\n",
      "Accuracy  : 0.9569 ± 0.0079\n",
      "Precision : 0.9645 ± 0.0100\n",
      "Recall    : 0.9272 ± 0.0146\n",
      "F1-score  : 0.9454 ± 0.0102\n"
     ]
    }
   ],
   "source": [
    "def pipeline_stratifiedKFold_and_training_RF(X_train, y_train, k=10):\n",
    "\n",
    "    list_accuracy_scores = []\n",
    "    list_precision_scores = []\n",
    "    list_recall_scores = []\n",
    "    list_f1_scores = []\n",
    "    skf = StratifiedKFold(n_splits=k, shuffle=True, random_state=42)\n",
    "\n",
    "    for i, (train_index, val_index) in enumerate(skf.split(X_train, y_train)):\n",
    "\n",
    "        # Récupération des sous-ensembles\n",
    "        X_tr = X_train.iloc[train_index]\n",
    "        X_val = X_train.iloc[val_index]\n",
    "        y_tr = y_train.iloc[train_index]\n",
    "        y_val = y_train.iloc[val_index]\n",
    "\n",
    "        print(f\"Fold {i}\")\n",
    "\n",
    "        # Modèle RandomForest\n",
    "        model = RandomForestClassifier(\n",
    "            n_estimators=300, # en ligne avec LGBM/CatBoost\n",
    "            max_depth=None, # laisse l’arbre croître (fort sur F1)\n",
    "            min_samples_split=2,\n",
    "            min_samples_leaf=1,\n",
    "            class_weight=\"balanced\", # Essentiel pour le dataset 60/40\n",
    "            random_state=42,\n",
    "            n_jobs=-1\n",
    "        )\n",
    "\n",
    "        # Entraînement\n",
    "        model.fit(X_tr, y_tr)\n",
    "\n",
    "        # Prédiction\n",
    "        y_pred = model.predict(X_val)\n",
    "\n",
    "        # Métriques\n",
    "        acc = accuracy_score(y_val, y_pred)\n",
    "        prec = precision_score(y_val, y_pred)\n",
    "        rec = recall_score(y_val, y_pred)\n",
    "        f1 = f1_score(y_val, y_pred)\n",
    "\n",
    "        list_accuracy_scores.append(acc)\n",
    "        list_precision_scores.append(prec)\n",
    "        list_recall_scores.append(rec)\n",
    "        list_f1_scores.append(f1)\n",
    "\n",
    "        print(f\"Accuracy : {acc:.4f}\")\n",
    "        print(f\"Precision: {prec:.4f}\")\n",
    "        print(f\"Recall   : {rec:.4f}\")\n",
    "        print(f\"F1-score : {f1:.4f}\")\n",
    "\n",
    "    # Moyenne et écart-type pour chaque métrique\n",
    "    avg_acc, std_acc = np.mean(list_accuracy_scores), np.std(list_accuracy_scores)\n",
    "    avg_prec, std_prec = np.mean(list_precision_scores), np.std(list_precision_scores)\n",
    "    avg_rec, std_rec = np.mean(list_recall_scores), np.std(list_recall_scores)\n",
    "    avg_f1, std_f1 = np.mean(list_f1_scores), np.std(list_f1_scores)\n",
    "\n",
    "    print(\"\\nAverage metrics over {} folds:\".format(k))\n",
    "    print(f\"Accuracy  : {avg_acc:.4f} ± {std_acc:.4f}\")\n",
    "    print(f\"Precision : {avg_prec:.4f} ± {std_prec:.4f}\")\n",
    "    print(f\"Recall    : {avg_rec:.4f} ± {std_rec:.4f}\")\n",
    "    print(f\"F1-score  : {avg_f1:.4f} ± {std_f1:.4f}\")\n",
    "\n",
    "    return ((avg_acc, std_acc), (avg_prec, std_prec), (avg_rec, std_rec), (avg_f1, std_f1))\n",
    "\n",
    "((avg_acc_rf, std_acc_rf),\n",
    " (avg_prec_rf, std_prec_rf),\n",
    " (avg_rec_rf, std_rec_rf),\n",
    " (avg_f1_rf, std_f1_rf)) = pipeline_stratifiedKFold_and_training_RF(X_train, y_train, k=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tableau recapitulatif"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Accuracy (avg ± std)</th>\n",
       "      <th>Precision (avg ± std)</th>\n",
       "      <th>Recall (avg ± std)</th>\n",
       "      <th>F1-score (avg ± std)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>MLP</td>\n",
       "      <td>0.8938 ± 0.0266</td>\n",
       "      <td>0.8713 ± 0.0243</td>\n",
       "      <td>0.8634 ± 0.0468</td>\n",
       "      <td>0.8672 ± 0.0354</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>XGBoost</td>\n",
       "      <td>0.9489 ± 0.0084</td>\n",
       "      <td>0.9431 ± 0.0152</td>\n",
       "      <td>0.9295 ± 0.0132</td>\n",
       "      <td>0.9361 ± 0.0104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CatBoost</td>\n",
       "      <td>0.9231 ± 0.0106</td>\n",
       "      <td>0.9323 ± 0.0119</td>\n",
       "      <td>0.8728 ± 0.0199</td>\n",
       "      <td>0.9015 ± 0.0142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>GradientBoosting</td>\n",
       "      <td>0.7799 ± 0.0102</td>\n",
       "      <td>0.8250 ± 0.0276</td>\n",
       "      <td>0.5775 ± 0.0211</td>\n",
       "      <td>0.6789 ± 0.0155</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ExtraTrees</td>\n",
       "      <td>0.9685 ± 0.0071</td>\n",
       "      <td>0.9670 ± 0.0106</td>\n",
       "      <td>0.9546 ± 0.0104</td>\n",
       "      <td>0.9607 ± 0.0089</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>RandomForest</td>\n",
       "      <td>0.9569 ± 0.0079</td>\n",
       "      <td>0.9645 ± 0.0100</td>\n",
       "      <td>0.9272 ± 0.0146</td>\n",
       "      <td>0.9454 ± 0.0102</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Model Accuracy (avg ± std) Precision (avg ± std)  \\\n",
       "0               MLP      0.8938 ± 0.0266       0.8713 ± 0.0243   \n",
       "1           XGBoost      0.9489 ± 0.0084       0.9431 ± 0.0152   \n",
       "2          CatBoost      0.9231 ± 0.0106       0.9323 ± 0.0119   \n",
       "3  GradientBoosting      0.7799 ± 0.0102       0.8250 ± 0.0276   \n",
       "4        ExtraTrees      0.9685 ± 0.0071       0.9670 ± 0.0106   \n",
       "5      RandomForest      0.9569 ± 0.0079       0.9645 ± 0.0100   \n",
       "\n",
       "  Recall (avg ± std) F1-score (avg ± std)  \n",
       "0    0.8634 ± 0.0468      0.8672 ± 0.0354  \n",
       "1    0.9295 ± 0.0132      0.9361 ± 0.0104  \n",
       "2    0.8728 ± 0.0199      0.9015 ± 0.0142  \n",
       "3    0.5775 ± 0.0211      0.6789 ± 0.0155  \n",
       "4    0.9546 ± 0.0104      0.9607 ± 0.0089  \n",
       "5    0.9272 ± 0.0146      0.9454 ± 0.0102  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "data = {\n",
    "    'Model': ['MLP', 'XGBoost', 'CatBoost', 'GradientBoosting', 'ExtraTrees', 'RandomForest'],\n",
    "    'Accuracy (avg ± std)': [\n",
    "        f\"{avg_acc_mlp:.4f} ± {std_acc_mlp:.4f}\",\n",
    "        f\"{avg_acc_xgb:.4f} ± {std_acc_xgb:.4f}\",\n",
    "        f\"{avg_acc_cb:.4f} ± {std_acc_cb:.4f}\",\n",
    "        f\"{avg_acc_gb:.4f} ± {std_acc_gb:.4f}\",\n",
    "        f\"{avg_acc_et:.4f} ± {std_acc_et:.4f}\",\n",
    "        f\"{avg_acc_rf:.4f} ± {std_acc_rf:.4f}\"\n",
    "    ],\n",
    "    'Precision (avg ± std)': [\n",
    "        f\"{avg_prec_mlp:.4f} ± {std_prec_mlp:.4f}\",\n",
    "        f\"{avg_prec_xgb:.4f} ± {std_prec_xgb:.4f}\",\n",
    "        f\"{avg_prec_cb:.4f} ± {std_prec_cb:.4f}\",\n",
    "        f\"{avg_prec_gb:.4f} ± {std_prec_gb:.4f}\",\n",
    "        f\"{avg_prec_et:.4f} ± {std_prec_et:.4f}\",\n",
    "        f\"{avg_prec_rf:.4f} ± {std_prec_rf:.4f}\"\n",
    "    ],\n",
    "    'Recall (avg ± std)': [\n",
    "        f\"{avg_rec_mlp:.4f} ± {std_rec_mlp:.4f}\",\n",
    "        f\"{avg_rec_xgb:.4f} ± {std_rec_xgb:.4f}\",\n",
    "        f\"{avg_rec_cb:.4f} ± {std_rec_cb:.4f}\",\n",
    "        f\"{avg_rec_gb:.4f} ± {std_rec_gb:.4f}\",\n",
    "        f\"{avg_rec_et:.4f} ± {std_rec_et:.4f}\",\n",
    "        f\"{avg_rec_rf:.4f} ± {std_rec_rf:.4f}\"\n",
    "    ],\n",
    "    'F1-score (avg ± std)': [\n",
    "        f\"{avg_f1_mlp:.4f} ± {std_f1_mlp:.4f}\",\n",
    "        f\"{avg_f1_xgb:.4f} ± {std_f1_xgb:.4f}\",\n",
    "        f\"{avg_f1_cb:.4f} ± {std_f1_cb:.4f}\",\n",
    "        f\"{avg_f1_gb:.4f} ± {std_f1_gb:.4f}\",\n",
    "        f\"{avg_f1_et:.4f} ± {std_f1_et:.4f}\",\n",
    "        f\"{avg_f1_rf:.4f} ± {std_f1_rf:.4f}\"\n",
    "    ]\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "df\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
