{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset1 = pd.read_csv('dalas/project/githubProject/ConflictPrediction/dataset1/dataset1_beforeSplit.csv')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TRAITEMENT SUR LE DATASET 1 (MASKED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train shape: (6610, 221)\n",
      "Test shape: (735, 221)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "\n",
    "## Code pour split le dataset 1 en train/test 90-10 %\n",
    "\n",
    "X = dataset1.drop(columns=['war'])\n",
    "y = dataset1['war']\n",
    "\n",
    "# Split train/test final\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X,y,\n",
    "    test_size=0.1,# 10% pour test\n",
    "    stratify=y, #pour garder la répartition des classes\n",
    "    random_state=42 #pour mettre une random seed fixe\n",
    ")\n",
    "\n",
    "print(\"Train shape:\", X_train.shape)\n",
    "print(\"Test shape:\", X_test.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 0\n",
      "F1-score : 0.9495\n",
      "Fold 1\n",
      "F1-score : 0.9582\n",
      "Fold 2\n",
      "F1-score : 0.9664\n",
      "Fold 3\n",
      "F1-score : 0.9472\n",
      "Fold 4\n",
      "F1-score : 0.9504\n",
      "Fold 5\n",
      "F1-score : 0.9502\n",
      "Fold 6\n",
      "F1-score : 0.9565\n",
      "Fold 7\n",
      "F1-score : 0.9516\n",
      "Fold 8\n",
      "F1-score : 0.9446\n",
      "Fold 9\n",
      "F1-score : 0.9562\n",
      "\n",
      "Average F1-score over 10 folds: 0.9531\n",
      "Standard Deviation of F1-score over 10 folds: 0.0060\n"
     ]
    }
   ],
   "source": [
    "import xgboost as xgb\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "\n",
    "# stratified K-fold cross-validation\n",
    "def pipeline_stratifiedKFold_and_training(X_train,y_train,k=10):\n",
    "    list_f1_scores = []\n",
    "    skf = StratifiedKFold(n_splits=k, shuffle=True,random_state=42) # shuffle pour mélanger les données avant de split \n",
    "\n",
    "    for i,(train_index,val_index) in enumerate(skf.split(X_train, y_train)):\n",
    "\n",
    "        # On récupère les sous-datasets d'entraînement et de validation\n",
    "        X_tr = X_train.iloc[train_index]\n",
    "        X_val=  X_train.iloc[val_index]\n",
    "        y_tr  = y_train.iloc[train_index] \n",
    "        y_val = y_train.iloc[val_index]\n",
    "\n",
    "        print(f\"Fold {i}\")\n",
    "        # Maintenant on entraine et évalue le modèle avec X_tr, y_tr, X_val, y_val\n",
    "\n",
    "        #### À REVOIR ###\n",
    "\n",
    "        # Modèle XGBoost\n",
    "        model = xgb.XGBClassifier(# Hyperparamètres à voir\n",
    "            n_estimators=100,\n",
    "            max_depth=5,\n",
    "            learning_rate=0.1,\n",
    "            random_state=42\n",
    "        )\n",
    "        # Entraînement\n",
    "        model.fit(X_tr, y_tr)\n",
    "\n",
    "        #Evaluation\n",
    "        y_pred = model.predict(X_val)\n",
    "         # Métriques\n",
    "        acc = accuracy_score(y_val, y_pred)\n",
    "        prec = precision_score(y_val, y_pred)\n",
    "        rec = recall_score(y_val, y_pred)\n",
    "        f1 = f1_score(y_val, y_pred)\n",
    "        list_f1_scores.append(f1)\n",
    "        #print(f\"Accuracy : {acc:.4f}\")\n",
    "        #print(f\"Precision: {prec:.4f}\")\n",
    "        #print(f\"Recall   : {rec:.4f}\")\n",
    "        print(f\"F1-score : {f1:.4f}\")\n",
    "\n",
    "    avg_f1 = np.mean(list_f1_scores)\n",
    "    print(f\"\\nAverage F1-score over {k} folds: {avg_f1:.4f}\")\n",
    "    std_f1 = np.std(list_f1_scores)\n",
    "    print(f\"Standard Deviation of F1-score over {k} folds: {std_f1:.4f}\")\n",
    "\n",
    "pipeline_stratifiedKFold_and_training(X_train, y_train, k=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TP Notebook",
   "language": "python",
   "name": ".venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
