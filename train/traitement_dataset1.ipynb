{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold, GridSearchCV\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, make_scorer\n",
    "\n",
    "import xgboost as xgb\n",
    "import lightgbm as lgb\n",
    "from catboost import CatBoostClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset1 = pd.read_csv('../dataset1/dataset1_beforeSplit.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TRAITEMENT SUR LE DATASET 1 (MASKED)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split en train/test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train shape: (6610, 221)\n",
      "Test shape: (735, 221)\n"
     ]
    }
   ],
   "source": [
    "## Code pour split le dataset 1 en train/test 90-10 %\n",
    "\n",
    "X = dataset1.drop(columns=['war'])\n",
    "y = dataset1['war']\n",
    "\n",
    "# Split train/test final\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X,y,\n",
    "    test_size=0.1,# 10% pour test\n",
    "    stratify=y, #pour garder la répartition des classes\n",
    "    random_state=42 #pour mettre une random seed fixe\n",
    ")\n",
    "\n",
    "print(\"Train shape:\", X_train.shape)\n",
    "print(\"Test shape:\", X_test.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Entraînement XGBoost avec StratifiedKFold + scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- Fold 0 --\n",
      "Accuracy : 0.9592\n",
      "Precision: 0.9478\n",
      "Recall   : 0.9513\n",
      "F1-score : 0.9495\n",
      "-- Fold 1 --\n",
      "Accuracy : 0.9667\n",
      "Precision: 0.9730\n",
      "Recall   : 0.9438\n",
      "F1-score : 0.9582\n",
      "-- Fold 2 --\n",
      "Accuracy : 0.9728\n",
      "Precision: 0.9628\n",
      "Recall   : 0.9700\n",
      "F1-score : 0.9664\n",
      "-- Fold 3 --\n",
      "Accuracy : 0.9576\n",
      "Precision: 0.9544\n",
      "Recall   : 0.9401\n",
      "F1-score : 0.9472\n",
      "-- Fold 4 --\n",
      "Accuracy : 0.9607\n",
      "Precision: 0.9689\n",
      "Recall   : 0.9326\n",
      "F1-score : 0.9504\n",
      "-- Fold 5 --\n",
      "Accuracy : 0.9607\n",
      "Precision: 0.9688\n",
      "Recall   : 0.9323\n",
      "F1-score : 0.9502\n",
      "-- Fold 6 --\n",
      "Accuracy : 0.9652\n",
      "Precision: 0.9620\n",
      "Recall   : 0.9511\n",
      "F1-score : 0.9565\n",
      "-- Fold 7 --\n",
      "Accuracy : 0.9622\n",
      "Precision: 0.9801\n",
      "Recall   : 0.9248\n",
      "F1-score : 0.9516\n",
      "-- Fold 8 --\n",
      "Accuracy : 0.9561\n",
      "Precision: 0.9611\n",
      "Recall   : 0.9286\n",
      "F1-score : 0.9446\n",
      "-- Fold 9 --\n",
      "Accuracy : 0.9652\n",
      "Precision: 0.9691\n",
      "Recall   : 0.9436\n",
      "F1-score : 0.9562\n",
      "\n",
      "Average metrics over 10 folds:\n",
      "Accuracy  : 0.9626 ± 0.0047\n",
      "Precision : 0.9648 ± 0.0088\n",
      "Recall    : 0.9418 ± 0.0127\n",
      "F1-score  : 0.9531 ± 0.0060\n"
     ]
    }
   ],
   "source": [
    "def pipeline_stratifiedKFold_and_training_XGBoost(X_train,y_train,k=10):\n",
    "    list_accuracy_scores = []\n",
    "    list_precision_scores = []\n",
    "    list_recall_scores = []\n",
    "    list_f1_scores = []\n",
    "    skf = StratifiedKFold(n_splits=k, shuffle=True,random_state=42) # shuffle pour mélanger les données avant de split \n",
    "\n",
    "    for i,(train_index,val_index) in enumerate(skf.split(X_train, y_train)):\n",
    "\n",
    "        # On récupère les sous-datasets d'entraînement et de validation\n",
    "        X_tr = X_train.iloc[train_index]\n",
    "        X_val=  X_train.iloc[val_index]\n",
    "        y_tr  = y_train.iloc[train_index] \n",
    "        y_val = y_train.iloc[val_index]\n",
    "\n",
    "        print(f\"-- Fold {i} --\")\n",
    "        \n",
    "        # Maintenant on entraine et évalue le modèle avec X_tr, y_tr, X_val, y_val\n",
    "\n",
    "        #### À REVOIR ###\n",
    "\n",
    "        # Modèle XGBoost\n",
    "        model = xgb.XGBClassifier( # Hyperparamètres à voir\n",
    "            n_estimators=100,\n",
    "            max_depth=5,\n",
    "            learning_rate=0.1,\n",
    "            random_state=42\n",
    "        )\n",
    "\n",
    "        # Entraînement\n",
    "        model.fit(X_tr, y_tr)\n",
    "\n",
    "        # Prédiction\n",
    "        y_pred = model.predict(X_val)\n",
    "\n",
    "        # Métriques\n",
    "        acc = accuracy_score(y_val, y_pred)\n",
    "        prec = precision_score(y_val, y_pred)\n",
    "        rec = recall_score(y_val, y_pred)\n",
    "        f1 = f1_score(y_val, y_pred)\n",
    "\n",
    "        list_accuracy_scores.append(acc)\n",
    "        list_precision_scores.append(prec)\n",
    "        list_recall_scores.append(rec)\n",
    "        list_f1_scores.append(f1)\n",
    "\n",
    "        print(f\"Accuracy : {acc:.4f}\")\n",
    "        print(f\"Precision: {prec:.4f}\")\n",
    "        print(f\"Recall   : {rec:.4f}\")\n",
    "        print(f\"F1-score : {f1:.4f}\")\n",
    "\n",
    "    # Moyenne et écart-type pour chaque métrique\n",
    "    avg_acc, std_acc = np.mean(list_accuracy_scores), np.std(list_accuracy_scores)\n",
    "    avg_prec, std_prec = np.mean(list_precision_scores), np.std(list_precision_scores)\n",
    "    avg_rec, std_rec = np.mean(list_recall_scores), np.std(list_recall_scores)\n",
    "    avg_f1, std_f1 = np.mean(list_f1_scores), np.std(list_f1_scores)\n",
    "\n",
    "    print(\"\\nAverage metrics over {} folds:\".format(k))\n",
    "    print(f\"Accuracy  : {avg_acc:.4f} ± {std_acc:.4f}\")\n",
    "    print(f\"Precision : {avg_prec:.4f} ± {std_prec:.4f}\")\n",
    "    print(f\"Recall    : {avg_rec:.4f} ± {std_rec:.4f}\")\n",
    "    print(f\"F1-score  : {avg_f1:.4f} ± {std_f1:.4f}\")\n",
    "\n",
    "    return ((avg_acc, std_acc), (avg_prec, std_prec), (avg_rec, std_rec), (avg_f1, std_f1))\n",
    "\n",
    "((avg_acc_xgb, std_acc_xgb), \n",
    " (avg_prec_xgb, std_prec_xgb), \n",
    " (avg_rec_xgb, std_rec_xgb), \n",
    " (avg_f1_xgb, std_f1_xgb)) = pipeline_stratifiedKFold_and_training_XGBoost(X_train, y_train, k=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Définition du modèle\n",
    "xgb_model = xgb.XGBClassifier(random_state=42, use_label_encoder=False, eval_metric='logloss')\n",
    "\n",
    "# Définition de la grille de paramètres à tester\n",
    "param_grid = {\n",
    "    'n_estimators': [100, 200, 300],\n",
    "    'max_depth': [3, 5, 7],\n",
    "    'learning_rate': [0.01, 0.05, 0.1],\n",
    "    'subsample': [0.7, 0.8, 1.0],\n",
    "    'colsample_bytree': [0.7, 0.8, 1.0]\n",
    "}\n",
    "\n",
    "# Stratified K-Fold pour garder la proportion des classes\n",
    "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# Scorer : ici on optimise le F1-score\n",
    "f1_scorer = make_scorer(f1_score)\n",
    "\n",
    "# GridSearchCV\n",
    "grid_search = GridSearchCV(\n",
    "    estimator=xgb_model,\n",
    "    param_grid=param_grid,\n",
    "    scoring=f1_scorer,\n",
    "    cv=skf,\n",
    "    verbose=1,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "# Lancement du tuning\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Résultats\n",
    "print(\"Meilleurs paramètres :\", grid_search.best_params_)\n",
    "print(\"Meilleur F1-score :\", grid_search.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Entraînement LightGBM avec StratifiedKFold + scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- Fold 0 --\n",
      "Accuracy : 0.9667\n",
      "Precision: 0.9588\n",
      "Recall   : 0.9588\n",
      "F1-score : 0.9588\n",
      "-- Fold 1 --\n",
      "Accuracy : 0.9652\n",
      "Precision: 0.9692\n",
      "Recall   : 0.9438\n",
      "F1-score : 0.9564\n",
      "-- Fold 2 --\n",
      "Accuracy : 0.9713\n",
      "Precision: 0.9627\n",
      "Recall   : 0.9663\n",
      "F1-score : 0.9645\n",
      "-- Fold 3 --\n",
      "Accuracy : 0.9622\n",
      "Precision: 0.9583\n",
      "Recall   : 0.9476\n",
      "F1-score : 0.9529\n",
      "-- Fold 4 --\n",
      "Accuracy : 0.9682\n",
      "Precision: 0.9767\n",
      "Recall   : 0.9438\n",
      "F1-score : 0.9600\n",
      "-- Fold 5 --\n",
      "Accuracy : 0.9728\n",
      "Precision: 0.9806\n",
      "Recall   : 0.9511\n",
      "F1-score : 0.9656\n",
      "-- Fold 6 --\n",
      "Accuracy : 0.9697\n",
      "Precision: 0.9659\n",
      "Recall   : 0.9586\n",
      "F1-score : 0.9623\n",
      "-- Fold 7 --\n",
      "Accuracy : 0.9758\n",
      "Precision: 0.9845\n",
      "Recall   : 0.9549\n",
      "F1-score : 0.9695\n",
      "-- Fold 8 --\n",
      "Accuracy : 0.9682\n",
      "Precision: 0.9730\n",
      "Recall   : 0.9474\n",
      "F1-score : 0.9600\n",
      "-- Fold 9 --\n",
      "Accuracy : 0.9667\n",
      "Precision: 0.9766\n",
      "Recall   : 0.9398\n",
      "F1-score : 0.9579\n",
      "\n",
      "Average metrics over 10 folds:\n",
      "Accuracy  : 0.9687 ± 0.0037\n",
      "Precision : 0.9706 ± 0.0087\n",
      "Recall    : 0.9512 ± 0.0079\n",
      "F1-score  : 0.9608 ± 0.0046\n"
     ]
    }
   ],
   "source": [
    "# Fonction de nettoyage des noms de colonnes pour LightGBM\n",
    "def clean_feature_names(df):\n",
    "    df = df.copy()\n",
    "    df.columns = df.columns.str.replace('[^A-Za-z0-9_]', '_', regex=True)\n",
    "    return df\n",
    "\n",
    "def pipeline_stratifiedKFold_and_training_LGBM(X_train, y_train, k=10):\n",
    "\n",
    "    X_train = clean_feature_names(X_train)\n",
    "\n",
    "    list_accuracy_scores = []\n",
    "    list_precision_scores = []\n",
    "    list_recall_scores = []\n",
    "    list_f1_scores = []\n",
    "    skf = StratifiedKFold(n_splits=k, shuffle=True, random_state=42)\n",
    "\n",
    "    for i, (train_index, val_index) in enumerate(skf.split(X_train, y_train)):\n",
    "\n",
    "        # Récupération des sous-ensembles\n",
    "        X_tr = X_train.iloc[train_index]\n",
    "        X_val = X_train.iloc[val_index]\n",
    "        y_tr = y_train.iloc[train_index]\n",
    "        y_val = y_train.iloc[val_index]\n",
    "\n",
    "        print(f\"-- Fold {i} --\")\n",
    "\n",
    "        # Modèle LightGBM\n",
    "        model = lgb.LGBMClassifier(\n",
    "            n_estimators=300,\n",
    "            learning_rate=0.05,\n",
    "            max_depth=-1,\n",
    "            num_leaves=31,\n",
    "            random_state=42,\n",
    "            verbose=0\n",
    "        )\n",
    "\n",
    "        # Entraînement\n",
    "        model.fit(X_tr, y_tr)\n",
    "\n",
    "        # Prédiction\n",
    "        y_pred = model.predict(X_val)\n",
    "\n",
    "        # Métriques\n",
    "        acc = accuracy_score(y_val, y_pred)\n",
    "        prec = precision_score(y_val, y_pred)\n",
    "        rec = recall_score(y_val, y_pred)\n",
    "        f1 = f1_score(y_val, y_pred)\n",
    "\n",
    "        list_accuracy_scores.append(acc)\n",
    "        list_precision_scores.append(prec)\n",
    "        list_recall_scores.append(rec)\n",
    "        list_f1_scores.append(f1)\n",
    "\n",
    "        print(f\"Accuracy : {acc:.4f}\")\n",
    "        print(f\"Precision: {prec:.4f}\")\n",
    "        print(f\"Recall   : {rec:.4f}\")\n",
    "        print(f\"F1-score : {f1:.4f}\")\n",
    "\n",
    "    # Moyenne et écart-type pour chaque métrique\n",
    "    avg_acc, std_acc = np.mean(list_accuracy_scores), np.std(list_accuracy_scores)\n",
    "    avg_prec, std_prec = np.mean(list_precision_scores), np.std(list_precision_scores)\n",
    "    avg_rec, std_rec = np.mean(list_recall_scores), np.std(list_recall_scores)\n",
    "    avg_f1, std_f1 = np.mean(list_f1_scores), np.std(list_f1_scores)\n",
    "\n",
    "    print(\"\\nAverage metrics over {} folds:\".format(k))\n",
    "    print(f\"Accuracy  : {avg_acc:.4f} ± {std_acc:.4f}\")\n",
    "    print(f\"Precision : {avg_prec:.4f} ± {std_prec:.4f}\")\n",
    "    print(f\"Recall    : {avg_rec:.4f} ± {std_rec:.4f}\")\n",
    "    print(f\"F1-score  : {avg_f1:.4f} ± {std_f1:.4f}\")\n",
    "\n",
    "    return ((avg_acc, std_acc), (avg_prec, std_prec), (avg_rec, std_rec), (avg_f1, std_f1))\n",
    "\n",
    "((avg_acc_lgb, std_acc_lgb),\n",
    " (avg_prec_lgb, std_prec_lgb),\n",
    " (avg_rec_lgb, std_rec_lgb),\n",
    " (avg_f1_lgb, std_f1_lgb)) = pipeline_stratifiedKFold_and_training_LGBM(X_train, y_train, k=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Entraînement CatBoost avec StratifiedKFold + scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 0\n",
      "Accuracy : 0.9667\n",
      "Precision: 0.9554\n",
      "Recall   : 0.9625\n",
      "F1-score : 0.9590\n",
      "Fold 1\n",
      "Accuracy : 0.9592\n",
      "Precision: 0.9688\n",
      "Recall   : 0.9288\n",
      "F1-score : 0.9484\n",
      "Fold 2\n",
      "Accuracy : 0.9758\n",
      "Precision: 0.9772\n",
      "Recall   : 0.9625\n",
      "F1-score : 0.9698\n",
      "Fold 3\n",
      "Accuracy : 0.9607\n",
      "Precision: 0.9547\n",
      "Recall   : 0.9476\n",
      "F1-score : 0.9511\n",
      "Fold 4\n",
      "Accuracy : 0.9667\n",
      "Precision: 0.9842\n",
      "Recall   : 0.9326\n",
      "F1-score : 0.9577\n",
      "Fold 5\n",
      "Accuracy : 0.9637\n",
      "Precision: 0.9764\n",
      "Recall   : 0.9323\n",
      "F1-score : 0.9538\n",
      "Fold 6\n",
      "Accuracy : 0.9697\n",
      "Precision: 0.9624\n",
      "Recall   : 0.9624\n",
      "F1-score : 0.9624\n",
      "Fold 7\n",
      "Accuracy : 0.9667\n",
      "Precision: 0.9766\n",
      "Recall   : 0.9398\n",
      "F1-score : 0.9579\n",
      "Fold 8\n",
      "Accuracy : 0.9576\n",
      "Precision: 0.9577\n",
      "Recall   : 0.9361\n",
      "F1-score : 0.9468\n",
      "Fold 9\n",
      "Accuracy : 0.9667\n",
      "Precision: 0.9692\n",
      "Recall   : 0.9474\n",
      "F1-score : 0.9582\n",
      "\n",
      "Average metrics over 10 folds:\n",
      "Accuracy  : 0.9654 ± 0.0051\n",
      "Precision : 0.9683 ± 0.0098\n",
      "Recall    : 0.9452 ± 0.0127\n",
      "F1-score  : 0.9565 ± 0.0065\n"
     ]
    }
   ],
   "source": [
    "def pipeline_stratifiedKFold_and_training_CatBoost(X_train, y_train, k=10):\n",
    "\n",
    "    list_accuracy_scores = []\n",
    "    list_precision_scores = []\n",
    "    list_recall_scores = []\n",
    "    list_f1_scores = []\n",
    "    skf = StratifiedKFold(n_splits=k, shuffle=True, random_state=42)\n",
    "\n",
    "    for i, (train_index, val_index) in enumerate(skf.split(X_train, y_train)):\n",
    "\n",
    "        # Récupération des sous-ensembles\n",
    "        X_tr = X_train.iloc[train_index]\n",
    "        X_val = X_train.iloc[val_index]\n",
    "        y_tr = y_train.iloc[train_index]\n",
    "        y_val = y_train.iloc[val_index]\n",
    "\n",
    "        print(f\"Fold {i}\")\n",
    "\n",
    "        # Modèle CatBoost\n",
    "        model = CatBoostClassifier(\n",
    "            iterations=300,\n",
    "            learning_rate=0.05,\n",
    "            depth=6, # équivalent à ~num_leaves mais plus stable\n",
    "            loss_function=\"Logloss\",\n",
    "            eval_metric=\"F1\",\n",
    "            random_seed=42,\n",
    "            verbose=False\n",
    "        )\n",
    "\n",
    "        # Entraînement\n",
    "        model.fit(X_tr, y_tr)\n",
    "\n",
    "        # Prédiction\n",
    "        y_pred = model.predict(X_val)\n",
    "\n",
    "        # Métriques\n",
    "        acc = accuracy_score(y_val, y_pred)\n",
    "        prec = precision_score(y_val, y_pred)\n",
    "        rec = recall_score(y_val, y_pred)\n",
    "        f1 = f1_score(y_val, y_pred)\n",
    "\n",
    "        list_accuracy_scores.append(acc)\n",
    "        list_precision_scores.append(prec)\n",
    "        list_recall_scores.append(rec)\n",
    "        list_f1_scores.append(f1)\n",
    "\n",
    "        print(f\"Accuracy : {acc:.4f}\")\n",
    "        print(f\"Precision: {prec:.4f}\")\n",
    "        print(f\"Recall   : {rec:.4f}\")\n",
    "        print(f\"F1-score : {f1:.4f}\")\n",
    "\n",
    "    # Moyenne et écart-type pour chaque métrique\n",
    "    avg_acc, std_acc = np.mean(list_accuracy_scores), np.std(list_accuracy_scores)\n",
    "    avg_prec, std_prec = np.mean(list_precision_scores), np.std(list_precision_scores)\n",
    "    avg_rec, std_rec = np.mean(list_recall_scores), np.std(list_recall_scores)\n",
    "    avg_f1, std_f1 = np.mean(list_f1_scores), np.std(list_f1_scores)\n",
    "\n",
    "    print(\"\\nAverage metrics over {} folds:\".format(k))\n",
    "    print(f\"Accuracy  : {avg_acc:.4f} ± {std_acc:.4f}\")\n",
    "    print(f\"Precision : {avg_prec:.4f} ± {std_prec:.4f}\")\n",
    "    print(f\"Recall    : {avg_rec:.4f} ± {std_rec:.4f}\")\n",
    "    print(f\"F1-score  : {avg_f1:.4f} ± {std_f1:.4f}\")\n",
    "\n",
    "    return ((avg_acc, std_acc), (avg_prec, std_prec), (avg_rec, std_rec), (avg_f1, std_f1))\n",
    "\n",
    "((avg_acc_cb, std_acc_cb),\n",
    " (avg_prec_cb, std_prec_cb),\n",
    " (avg_rec_cb, std_rec_cb), \n",
    " (avg_f1_cb, std_f1_cb)) = pipeline_stratifiedKFold_and_training_CatBoost(X_train, y_train, k=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Entraînement Random Forest avec StratifiedKFold + scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 0\n",
      "Accuracy : 0.9682\n",
      "Precision: 0.9556\n",
      "Recall   : 0.9663\n",
      "F1-score : 0.9609\n",
      "Fold 1\n",
      "Accuracy : 0.9667\n",
      "Precision: 0.9804\n",
      "Recall   : 0.9363\n",
      "F1-score : 0.9579\n",
      "Fold 2\n",
      "Accuracy : 0.9697\n",
      "Precision: 0.9660\n",
      "Recall   : 0.9588\n",
      "F1-score : 0.9624\n",
      "Fold 3\n",
      "Accuracy : 0.9622\n",
      "Precision: 0.9618\n",
      "Recall   : 0.9438\n",
      "F1-score : 0.9527\n",
      "Fold 4\n",
      "Accuracy : 0.9743\n",
      "Precision: 0.9808\n",
      "Recall   : 0.9551\n",
      "F1-score : 0.9677\n",
      "Fold 5\n",
      "Accuracy : 0.9652\n",
      "Precision: 0.9765\n",
      "Recall   : 0.9361\n",
      "F1-score : 0.9559\n",
      "Fold 6\n",
      "Accuracy : 0.9637\n",
      "Precision: 0.9618\n",
      "Recall   : 0.9474\n",
      "F1-score : 0.9545\n",
      "Fold 7\n",
      "Accuracy : 0.9697\n",
      "Precision: 0.9767\n",
      "Recall   : 0.9474\n",
      "F1-score : 0.9618\n",
      "Fold 8\n",
      "Accuracy : 0.9667\n",
      "Precision: 0.9766\n",
      "Recall   : 0.9398\n",
      "F1-score : 0.9579\n",
      "Fold 9\n",
      "Accuracy : 0.9682\n",
      "Precision: 0.9880\n",
      "Recall   : 0.9323\n",
      "F1-score : 0.9594\n",
      "\n",
      "Average metrics over 10 folds:\n",
      "Accuracy  : 0.9675 ± 0.0033\n",
      "Precision : 0.9724 ± 0.0099\n",
      "Recall    : 0.9463 ± 0.0104\n",
      "F1-score  : 0.9591 ± 0.0041\n"
     ]
    }
   ],
   "source": [
    "def pipeline_stratifiedKFold_and_training_RF(X_train, y_train, k=10):\n",
    "\n",
    "    list_accuracy_scores = []\n",
    "    list_precision_scores = []\n",
    "    list_recall_scores = []\n",
    "    list_f1_scores = []\n",
    "    skf = StratifiedKFold(n_splits=k, shuffle=True, random_state=42)\n",
    "\n",
    "    for i, (train_index, val_index) in enumerate(skf.split(X_train, y_train)):\n",
    "\n",
    "        # Récupération des sous-ensembles\n",
    "        X_tr = X_train.iloc[train_index]\n",
    "        X_val = X_train.iloc[val_index]\n",
    "        y_tr = y_train.iloc[train_index]\n",
    "        y_val = y_train.iloc[val_index]\n",
    "\n",
    "        print(f\"Fold {i}\")\n",
    "\n",
    "        # Modèle RandomForest\n",
    "        model = RandomForestClassifier(\n",
    "            n_estimators=300, # en ligne avec LGBM/CatBoost\n",
    "            max_depth=None, # laisse l’arbre croître (fort sur F1)\n",
    "            min_samples_split=2,\n",
    "            min_samples_leaf=1,\n",
    "            class_weight=\"balanced\", # Essentiel pour le dataset 60/40\n",
    "            random_state=42,\n",
    "            n_jobs=-1\n",
    "        )\n",
    "\n",
    "        # Entraînement\n",
    "        model.fit(X_tr, y_tr)\n",
    "\n",
    "        # Prédiction\n",
    "        y_pred = model.predict(X_val)\n",
    "\n",
    "        # Métriques\n",
    "        acc = accuracy_score(y_val, y_pred)\n",
    "        prec = precision_score(y_val, y_pred)\n",
    "        rec = recall_score(y_val, y_pred)\n",
    "        f1 = f1_score(y_val, y_pred)\n",
    "\n",
    "        list_accuracy_scores.append(acc)\n",
    "        list_precision_scores.append(prec)\n",
    "        list_recall_scores.append(rec)\n",
    "        list_f1_scores.append(f1)\n",
    "\n",
    "        print(f\"Accuracy : {acc:.4f}\")\n",
    "        print(f\"Precision: {prec:.4f}\")\n",
    "        print(f\"Recall   : {rec:.4f}\")\n",
    "        print(f\"F1-score : {f1:.4f}\")\n",
    "\n",
    "    # Moyenne et écart-type pour chaque métrique\n",
    "    avg_acc, std_acc = np.mean(list_accuracy_scores), np.std(list_accuracy_scores)\n",
    "    avg_prec, std_prec = np.mean(list_precision_scores), np.std(list_precision_scores)\n",
    "    avg_rec, std_rec = np.mean(list_recall_scores), np.std(list_recall_scores)\n",
    "    avg_f1, std_f1 = np.mean(list_f1_scores), np.std(list_f1_scores)\n",
    "\n",
    "    print(\"\\nAverage metrics over {} folds:\".format(k))\n",
    "    print(f\"Accuracy  : {avg_acc:.4f} ± {std_acc:.4f}\")\n",
    "    print(f\"Precision : {avg_prec:.4f} ± {std_prec:.4f}\")\n",
    "    print(f\"Recall    : {avg_rec:.4f} ± {std_rec:.4f}\")\n",
    "    print(f\"F1-score  : {avg_f1:.4f} ± {std_f1:.4f}\")\n",
    "\n",
    "    return ((avg_acc, std_acc), (avg_prec, std_prec), (avg_rec, std_rec), (avg_f1, std_f1))\n",
    "\n",
    "((avg_acc_rf, std_acc_rf),\n",
    " (avg_prec_rf, std_prec_rf),\n",
    " (avg_rec_rf, std_rec_rf),\n",
    " (avg_f1_rf, std_f1_rf)) = pipeline_stratifiedKFold_and_training_RF(X_train, y_train, k=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tableau recapitulatif"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Accuracy (avg ± std)</th>\n",
       "      <th>Precision (avg ± std)</th>\n",
       "      <th>Recall (avg ± std)</th>\n",
       "      <th>F1-score (avg ± std)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>XGBoost</td>\n",
       "      <td>0.9626 ± 0.0047</td>\n",
       "      <td>0.9648 ± 0.0088</td>\n",
       "      <td>0.9418 ± 0.0127</td>\n",
       "      <td>0.9531 ± 0.0060</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>LightGBM</td>\n",
       "      <td>0.9687 ± 0.0037</td>\n",
       "      <td>0.9706 ± 0.0087</td>\n",
       "      <td>0.9512 ± 0.0079</td>\n",
       "      <td>0.9608 ± 0.0046</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CatBoost</td>\n",
       "      <td>0.9654 ± 0.0051</td>\n",
       "      <td>0.9683 ± 0.0098</td>\n",
       "      <td>0.9452 ± 0.0127</td>\n",
       "      <td>0.9565 ± 0.0065</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>RandomForest</td>\n",
       "      <td>0.9675 ± 0.0033</td>\n",
       "      <td>0.9724 ± 0.0099</td>\n",
       "      <td>0.9463 ± 0.0104</td>\n",
       "      <td>0.9591 ± 0.0041</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Model Accuracy (avg ± std) Precision (avg ± std) Recall (avg ± std)  \\\n",
       "0       XGBoost      0.9626 ± 0.0047       0.9648 ± 0.0088    0.9418 ± 0.0127   \n",
       "1      LightGBM      0.9687 ± 0.0037       0.9706 ± 0.0087    0.9512 ± 0.0079   \n",
       "2      CatBoost      0.9654 ± 0.0051       0.9683 ± 0.0098    0.9452 ± 0.0127   \n",
       "3  RandomForest      0.9675 ± 0.0033       0.9724 ± 0.0099    0.9463 ± 0.0104   \n",
       "\n",
       "  F1-score (avg ± std)  \n",
       "0      0.9531 ± 0.0060  \n",
       "1      0.9608 ± 0.0046  \n",
       "2      0.9565 ± 0.0065  \n",
       "3      0.9591 ± 0.0041  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = {\n",
    "        'Model': ['XGBoost', 'LightGBM', 'CatBoost', 'RandomForest'],\n",
    "        'Accuracy (avg ± std)': [f\"{avg_acc_xgb:.4f} ± {std_acc_xgb:.4f}\",\n",
    "                                f\"{avg_acc_lgb:.4f} ± {std_acc_lgb:.4f}\",\n",
    "                                f\"{avg_acc_cb:.4f} ± {std_acc_cb:.4f}\",\n",
    "                                f\"{avg_acc_rf:.4f} ± {std_acc_rf:.4f}\"],\n",
    "        'Precision (avg ± std)': [f\"{avg_prec_xgb:.4f} ± {std_prec_xgb:.4f}\",\n",
    "                                f\"{avg_prec_lgb:.4f} ± {std_prec_lgb:.4f}\",\n",
    "                                f\"{avg_prec_cb:.4f} ± {std_prec_cb:.4f}\",\n",
    "                                f\"{avg_prec_rf:.4f} ± {std_prec_rf:.4f}\"],\n",
    "        'Recall (avg ± std)': [f\"{avg_rec_xgb:.4f} ± {std_rec_xgb:.4f}\",\n",
    "                        f\"{avg_rec_lgb:.4f} ± {std_rec_lgb:.4f}\",\n",
    "                        f\"{avg_rec_cb:.4f} ± {std_rec_cb:.4f}\",\n",
    "                        f\"{avg_rec_rf:.4f} ± {std_rec_rf:.4f}\"],\n",
    "        'F1-score (avg ± std)': [f\"{avg_f1_xgb:.4f} ± {std_f1_xgb:.4f}\",\n",
    "                                f\"{avg_f1_lgb:.4f} ± {std_f1_lgb:.4f}\",\n",
    "                                f\"{avg_f1_cb:.4f} ± {std_f1_cb:.4f}\",\n",
    "                                f\"{avg_f1_rf:.4f} ± {std_f1_rf:.4f}\"]\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
